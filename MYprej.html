<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MediSim AI - Medical Communication Trainer</title>
    
    <!-- React & ReactDOM -->
    <script crossorigin src="https://unpkg.com/react@18/umd/react.production.min.js"></script>
    <script crossorigin src="https://unpkg.com/react-dom@18/umd/react-dom.production.min.js"></script>
    
    <!-- Babel -->
    <script src="https://unpkg.com/@babel/standalone/babel.min.js"></script>
    
    <!-- Tailwind CSS -->
    <script src="https://cdn.tailwindcss.com"></script>
    
    <!-- Lucide Icons -->
    <script src="https://unpkg.com/lucide@latest"></script>
    
    <!-- Fonts -->
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

    <style>
        body { font-family: 'Inter', sans-serif; background-color: #0f172a; color: #e2e8f0; }
        .glass-panel { background: rgba(30, 41, 59, 0.7); backdrop-filter: blur(12px); border: 1px solid rgba(255, 255, 255, 0.1); }
        .custom-scrollbar::-webkit-scrollbar { width: 6px; }
        .custom-scrollbar::-webkit-scrollbar-track { background: rgba(0,0,0,0.1); }
        .custom-scrollbar::-webkit-scrollbar-thumb { background: rgba(255,255,255,0.2); border-radius: 3px; }
        .mic-pulse { animation: pulse-ring 2s cubic-bezier(0.215, 0.61, 0.355, 1) infinite; }
        @keyframes pulse-ring {
            0% { transform: scale(0.95); box-shadow: 0 0 0 0 rgba(14, 165, 233, 0.7); }
            70% { transform: scale(1); box-shadow: 0 0 0 20px rgba(14, 165, 233, 0); }
            100% { transform: scale(0.95); box-shadow: 0 0 0 0 rgba(14, 165, 233, 0); }
        }
        .markdown-content ul { list-style-type: disc; padding-left: 1.5rem; margin-bottom: 1rem; }
        .markdown-content li { margin-bottom: 0.5rem; }
        .markdown-content strong { color: #38bdf8; }
    </style>
</head>
<body>
    <div id="root"></div>

    <script type="text/babel">
        const { useState, useEffect, useRef, useMemo } = React;
        
        // --- System Constants ---
        const apiKey = ""; // API Key provided by environment
        const MODEL_TEXT = "gemini-2.5-flash-preview-09-2025";
        const MODEL_TTS = "gemini-2.5-flash-preview-tts";

        // --- Helper: Lucide Icon Component ---
        const Icon = ({ name, size = 20, className = "" }) => {
            const lucide = window.lucide;
            if (!lucide) return null;
            const IconComponent = lucide.icons[name];
            if (!IconComponent) return null;
            
            // Convert the icon to an SVG string and render it dangerously to work with React in this CDN setup
            // Or simpler: just use an <i> tag which lucide replaces, but for React purely:
            return (
                <svg 
                    xmlns="http://www.w3.org/2000/svg" 
                    width={size} 
                    height={size} 
                    viewBox="0 0 24 24" 
                    fill="none" 
                    stroke="currentColor" 
                    strokeWidth="2" 
                    strokeLinecap="round" 
                    strokeLinejoin="round" 
                    className={`lucide lucide-${name} ${className}`}
                    dangerouslySetInnerHTML={{ __html: lucide.icons[name].toSvg().match(/>(.*)<\/svg>/)[1] }}
                />
            );
        };

        // --- Main App Component ---
        function App() {
            // View State: 'setup', 'sim', 'report', 'architecture'
            const [view, setView] = useState('setup');
            const [loading, setLoading] = useState(false);
            
            // Simulation Configuration
            const [config, setConfig] = useState({
                scenario: 'cancer_diagnosis',
                patientAge: '55',
                patientName: 'Robert',
                emotionalBaseline: 'anxious',
                difficulty: 'normal'
            });

            // Session Data
            const [conversation, setConversation] = useState([]); // Array of {role: 'doctor'|'patient', text: '', emotion: ''}
            const [currentEmotion, setCurrentEmotion] = useState(config.emotionalBaseline);
            const [evaluation, setEvaluation] = useState(null);
            const [isRecording, setIsRecording] = useState(false);
            const [isSpeaking, setIsSpeaking] = useState(false);
            
            // Refs
            const recognitionRef = useRef(null);
            const audioRef = useRef(null);
            const chatEndRef = useRef(null);
            
            // State Ref (Fixes stale closure in Event Listeners)
            const stateRef = useRef({ conversation, currentEmotion });

            // Keep stateRef in sync with actual state
            useEffect(() => {
                stateRef.current = { conversation, currentEmotion };
            }, [conversation, currentEmotion]);

            // --- Initialization ---
            useEffect(() => {
                // Initialize Speech Recognition
                const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
                if (SpeechRecognition) {
                    const recognition = new SpeechRecognition();
                    recognition.continuous = false;
                    recognition.lang = 'en-US';
                    recognition.interimResults = false;
                    
                    recognition.onresult = (event) => {
                        const transcript = event.results[0][0].transcript;
                        handleDoctorInput(transcript);
                    };
                    
                    recognition.onerror = (event) => {
                        console.error("Speech recognition error", event.error);
                        setIsRecording(false);
                    };

                    recognition.onend = () => {
                        setIsRecording(false);
                    };

                    recognitionRef.current = recognition;
                }
            }, [config]); // Re-init if config changes significantly (not strictly needed but safer)

            useEffect(() => {
                if (chatEndRef.current) {
                    chatEndRef.current.scrollIntoView({ behavior: 'smooth' });
                }
            }, [conversation]);

            // --- Core Logic: Patient Simulation ---
            const handleDoctorInput = async (text) => {
                setIsRecording(false);
                
                // Get fresh state from ref to avoid closure staleness issues
                const { conversation: history, currentEmotion: emotion } = stateRef.current;
                
                // 1. Update State with Doctor's input
                const newHistory = [...history, { role: 'doctor', text: text }];
                setConversation(newHistory);
                setLoading(true);

                try {
                    // 2. Construct Prompt for Gemini
                    const systemPrompt = `
                        You are a highly realistic medical patient simulation for training doctors. 
                        Your name is ${config.patientName}, Age: ${config.patientAge}.
                        Scenario: ${getScenarioDescription(config.scenario)}.
                        Current Emotional State: ${emotion}.
                        
                        INSTRUCTIONS:
                        1. Respond to the doctor's input naturally. Do NOT be an AI. Be a human.
                        2. React emotionally. If the doctor is dismissive, get angry/shut down. If empathetic, open up.
                        3. Keep responses concise (spoken length).
                        4. Output MUST be valid JSON only. No markdown formatting.
                        
                        JSON Structure:
                        {
                            "internal_thought": "Brief reasoning about doctor's words",
                            "new_emotional_state": "one of: Anxious, Angry, Confused, Relieved, Sad, Neutral",
                            "spoken_response": "The actual dialogue"
                        }
                    `;

                    const chatHistory = newHistory.map(turn => `${turn.role.toUpperCase()}: ${turn.text}`).join('\n');
                    
                    const payload = {
                        contents: [{ parts: [{ text: systemPrompt + "\n\nConversation So Far:\n" + chatHistory + "\n\nPATIENT RESPONSE (JSON):" }] }]
                    };

                    // 3. Call Gemini for Text & Emotion
                    const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/${MODEL_TEXT}:generateContent?key=${apiKey}`, {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify(payload)
                    });

                    const data = await response.json();
                    let rawText = data.candidates[0].content.parts[0].text;
                    
                    // Cleanup JSON (sometimes model adds ```json ... ```)
                    rawText = rawText.replace(/```json/g, '').replace(/```/g, '').trim();
                    const patientData = JSON.parse(rawText);

                    // 4. Update Conversation
                    setConversation(prev => [...prev, { 
                        role: 'patient', 
                        text: patientData.spoken_response, 
                        emotion: patientData.new_emotional_state,
                        thought: patientData.internal_thought
                    }]);
                    setCurrentEmotion(patientData.new_emotional_state);

                    // 5. Generate Audio (TTS)
                    await playTTS(patientData.spoken_response);

                } catch (error) {
                    console.error("AI Error:", error);
                    alert("Simulation error. Please check console/network.");
                } finally {
                    setLoading(false);
                }
            };

            // --- Core Logic: TTS ---
            const playTTS = async (text) => {
                setIsSpeaking(true);
                try {
                    const payload = {
                        contents: [{ parts: [{ text: text }] }],
                        generationConfig: {
                            responseModalities: ["AUDIO"],
                            speechConfig: {
                                voiceConfig: {
                                    prebuiltVoiceConfig: {
                                        voiceName: "Fenrir" // Deep, calm male voice. Use 'Kore' for female.
                                    }
                                }
                            }
                        }
                    };

                    const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/${MODEL_TTS}:generateContent?key=${apiKey}`, {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify(payload)
                    });

                    const data = await response.json();
                    
                    // The Gemini TTS model returns raw PCM data in the response
                    // We need to wrap it in a WAV container to play it in the browser
                    if (data.candidates && data.candidates[0].content.parts[0].inlineData) {
                        const inlineData = data.candidates[0].content.parts[0].inlineData;
                        const audioContent = inlineData.data;
                        
                        // Parse sample rate from mimeType if available (e.g. "audio/pcm; rate=24000")
                        let sampleRate = 24000; // Default for this model
                        if (inlineData.mimeType) {
                            const match = inlineData.mimeType.match(/rate=(\d+)/);
                            if (match) {
                                sampleRate = parseInt(match[1], 10);
                            }
                        }

                        // Convert Base64 to ArrayBuffer (Raw PCM)
                        const pcmData = base64ToArrayBuffer(audioContent);
                        
                        // Wrap in WAV header
                        const wavData = pcmToWav(pcmData, sampleRate);
                        
                        const audioBlob = new Blob([wavData], { type: 'audio/wav' });
                        const audioUrl = URL.createObjectURL(audioBlob);
                        
                        const audio = new Audio(audioUrl);
                        audio.onended = () => setIsSpeaking(false);
                        
                        // Wait for playback to start. If it fails (NotSupportedError), catch block handles fallback.
                        await audio.play();
                    } else {
                        throw new Error("No audio data");
                    }

                } catch (e) {
                    console.warn("Gemini TTS failed, falling back to browser TTS", e);
                    // Fallback to browser TTS
                    const utterance = new SpeechSynthesisUtterance(text);
                    utterance.onend = () => setIsSpeaking(false);
                    window.speechSynthesis.speak(utterance);
                }
            };

            const base64ToArrayBuffer = (base64) => {
                const binaryString = window.atob(base64);
                const len = binaryString.length;
                const bytes = new Uint8Array(len);
                for (let i = 0; i < len; i++) {
                    bytes[i] = binaryString.charCodeAt(i);
                }
                return bytes.buffer;
            };

            // Adds a WAV header to the raw PCM data
            const pcmToWav = (pcmData, sampleRate = 24000) => {
                const numChannels = 1;
                const bitsPerSample = 16;
                const byteRate = (sampleRate * numChannels * bitsPerSample) / 8;
                const blockAlign = (numChannels * bitsPerSample) / 8;
                const dataSize = pcmData.byteLength;
                const buffer = new ArrayBuffer(44 + dataSize);
                const view = new DataView(buffer);

                // RIFF chunk descriptor
                writeString(view, 0, 'RIFF');
                view.setUint32(4, 36 + dataSize, true);
                writeString(view, 8, 'WAVE');

                // fmt sub-chunk
                writeString(view, 12, 'fmt ');
                view.setUint32(16, 16, true); // Subchunk1Size (16 for PCM)
                view.setUint16(20, 1, true); // AudioFormat (1 for PCM)
                view.setUint16(22, numChannels, true); // NumChannels
                view.setUint32(24, sampleRate, true); // SampleRate
                view.setUint32(28, byteRate, true); // ByteRate
                view.setUint16(32, blockAlign, true); // BlockAlign
                view.setUint16(34, bitsPerSample, true); // BitsPerSample

                // data sub-chunk
                writeString(view, 36, 'data');
                view.setUint32(40, dataSize, true);

                // Write PCM data
                const pcmBytes = new Uint8Array(pcmData);
                const wavBytes = new Uint8Array(buffer, 44);
                wavBytes.set(pcmBytes);

                return buffer;
            };

            const writeString = (view, offset, string) => {
                for (let i = 0; i < string.length; i++) {
                    view.setUint8(offset + i, string.charCodeAt(i));
                }
            };

            // --- Core Logic: Evaluation Engine ---
            const generateReport = async () => {
                setLoading(true);
                try {
                    const transcript = conversation.map(t => `${t.role.toUpperCase()}: ${t.text}`).join('\n');
                    const evalPrompt = `
                        Role: You are a Medical Communication Expert and Senior Attending Physician.
                        Task: Evaluate the following doctor-patient transcript.
                        Context: The patient was ${config.emotionalBaseline} with ${config.scenario}.
                        
                        Transcript:
                        ${transcript}
                        
                        Output Requirement: Return strict JSON. No markdown.
                        {
                            "empathy_score": (1-100),
                            "clarity_score": (1-100),
                            "emotional_intelligence_score": (1-100),
                            "key_strengths": ["point 1", "point 2"],
                            "areas_for_improvement": ["point 1", "point 2"],
                            "specific_feedback": "Paragraph summarizing performance.",
                            "better_alternatives": [
                                {"original": "Quote from doctor", "suggestion": "Better way to say it", "reason": "Why the suggestion is better"}
                            ]
                        }
                    `;

                    const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/${MODEL_TEXT}:generateContent?key=${apiKey}`, {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify({ contents: [{ parts: [{ text: evalPrompt }] }] })
                    });

                    const data = await response.json();
                    let rawText = data.candidates[0].content.parts[0].text;
                    rawText = rawText.replace(/```json/g, '').replace(/```/g, '').trim();
                    setEvaluation(JSON.parse(rawText));
                    setView('report');

                } catch (e) {
                    console.error("Evaluation Failed", e);
                    alert("Failed to generate report.");
                } finally {
                    setLoading(false);
                }
            };

            const getScenarioDescription = (key) => {
                const scenarios = {
                    cancer_diagnosis: "You have just been told you might have pancreatic cancer. You are terrified about your family.",
                    chronic_pain: "You have had back pain for 3 years. Doctors treat you like a drug seeker. You are frustrated and cynical.",
                    minor_illness: "You have a flu but you are a hypochondriac convinced it is meningitis."
                };
                return scenarios[key];
            };

            // --- Render Components ---

            const ArchitectureView = () => (
                <div className="p-8 max-w-4xl mx-auto text-slate-300">
                    <h2 className="text-3xl font-bold text-white mb-6 border-b border-slate-700 pb-4">System Architecture & Design</h2>
                    
                    <div className="grid grid-cols-1 md:grid-cols-2 gap-8">
                        <div className="glass-panel p-6 rounded-xl">
                            <h3 className="text-xl font-semibold text-cyan-400 mb-4">1. Core Components</h3>
                            <ul className="space-y-3 text-sm">
                                <li className="flex items-start gap-2"><div className="w-1.5 h-1.5 mt-1.5 bg-cyan-400 rounded-full"></div><span><strong>Client-Side Engine:</strong> React 18 SPA. No backend required for privacy & latency.</span></li>
                                <li className="flex items-start gap-2"><div className="w-1.5 h-1.5 mt-1.5 bg-cyan-400 rounded-full"></div><span><strong>LLM Brain:</strong> Gemini 2.5 Flash for low-latency Persona generation and complex Evaluation.</span></li>
                                <li className="flex items-start gap-2"><div className="w-1.5 h-1.5 mt-1.5 bg-cyan-400 rounded-full"></div><span><strong>Audio Pipeline:</strong> Web Speech API (Input) + Gemini TTS (Output) for "Speech-to-Speech" simulation.</span></li>
                                <li className="flex items-start gap-2"><div className="w-1.5 h-1.5 mt-1.5 bg-cyan-400 rounded-full"></div><span><strong>State Manager:</strong> Chain-of-Thought JSON logic tracks "Hidden Emotion" separate from "Spoken Output".</span></li>
                            </ul>
                        </div>

                        <div className="glass-panel p-6 rounded-xl">
                            <h3 className="text-xl font-semibold text-cyan-400 mb-4">2. Interaction Flow</h3>
                            <div className="text-sm font-mono bg-slate-900 p-3 rounded border border-slate-700">
                                User Audio → <br/>
                                STT (Text) → <br/>
                                Context Injection (Scenario + History) → <br/>
                                Gemini (Reasoning + Emotion Update) → <br/>
                                TTS Audio Generation → <br/>
                                User Hears Response
                            </div>
                        </div>
                    </div>

                    <div className="mt-8 glass-panel p-6 rounded-xl">
                        <h3 className="text-xl font-semibold text-cyan-400 mb-4">3. Ethical & Safety Constraints</h3>
                        <div className="grid grid-cols-1 md:grid-cols-3 gap-4 text-sm">
                            <div className="p-3 bg-slate-800/50 rounded">
                                <strong className="text-white block mb-1">Bias Mitigation</strong>
                                System prompts explicitly randomize persona responses to avoid stereotypes unless configured specifically for cultural competency training.
                            </div>
                            <div className="p-3 bg-slate-800/50 rounded">
                                <strong className="text-white block mb-1">Not a Real Doctor</strong>
                                UI persistently displays "SIMULATION MODE" to prevent confusion. Medical advice generated is labeled as roleplay.
                            </div>
                            <div className="p-3 bg-slate-800/50 rounded">
                                <strong className="text-white block mb-1">Emotional Safety</strong>
                                Scenarios have hard-limits on aggression intensity to protect the trainee from abusive AI outputs.
                            </div>
                        </div>
                    </div>

                    <button onClick={() => setView('setup')} className="mt-8 px-6 py-2 bg-slate-700 hover:bg-slate-600 rounded-lg text-white transition">
                        Back to App
                    </button>
                </div>
            );

            const SetupView = () => (
                <div className="flex flex-col items-center justify-center min-h-screen p-4">
                    <div className="glass-panel p-8 rounded-2xl max-w-lg w-full shadow-2xl">
                        <div className="flex items-center gap-3 mb-6 text-cyan-400">
                            <Icon name="activity" size={32} />
                            <h1 className="text-2xl font-bold tracking-tight text-white">MediSim AI</h1>
                        </div>
                        
                        <p className="text-slate-400 mb-8">Configure your simulation session. This tool helps you practice empathy and clarity in difficult conversations.</p>

                        <div className="space-y-5">
                            <div>
                                <label className="block text-sm font-medium text-slate-300 mb-2">Clinical Scenario</label>
                                <select 
                                    className="w-full bg-slate-900 border border-slate-700 text-white rounded-lg p-3 focus:ring-2 focus:ring-cyan-500 outline-none"
                                    value={config.scenario}
                                    onChange={(e) => setConfig({...config, scenario: e.target.value})}
                                >
                                    <option value="cancer_diagnosis">Breaking Bad News (Oncology)</option>
                                    <option value="chronic_pain">Chronic Pain Management</option>
                                    <option value="minor_illness">Anxious Patient (Minor Illness)</option>
                                </select>
                            </div>

                            <div className="grid grid-cols-2 gap-4">
                                <div>
                                    <label className="block text-sm font-medium text-slate-300 mb-2">Patient Age</label>
                                    <input 
                                        type="number" 
                                        value={config.patientAge}
                                        onChange={(e) => setConfig({...config, patientAge: e.target.value})}
                                        className="w-full bg-slate-900 border border-slate-700 text-white rounded-lg p-3 outline-none"
                                    />
                                </div>
                                <div>
                                    <label className="block text-sm font-medium text-slate-300 mb-2">Baseline Emotion</label>
                                    <select 
                                        className="w-full bg-slate-900 border border-slate-700 text-white rounded-lg p-3 outline-none"
                                        value={config.emotionalBaseline}
                                        onChange={(e) => setConfig({...config, emotionalBaseline: e.target.value})}
                                    >
                                        <option value="anxious">Anxious</option>
                                        <option value="angry">Frustrated/Angry</option>
                                        <option value="confused">Confused</option>
                                        <option value="denial">In Denial</option>
                                    </select>
                                </div>
                            </div>
                        </div>

                        <div className="flex gap-4 mt-8">
                            <button 
                                onClick={() => {
                                    setConversation([]);
                                    setCurrentEmotion(config.emotionalBaseline);
                                    setView('sim');
                                }}
                                className="flex-1 bg-cyan-500 hover:bg-cyan-400 text-slate-900 font-bold py-3 rounded-lg transition shadow-lg shadow-cyan-500/20"
                            >
                                Start Simulation
                            </button>
                            <button 
                                onClick={() => setView('architecture')}
                                className="px-4 py-3 border border-slate-600 rounded-lg hover:bg-slate-800 transition text-slate-400"
                            >
                                <Icon name="cpu" size={20} />
                            </button>
                        </div>
                    </div>
                </div>
            );

            const SimulationView = () => (
                <div className="flex flex-col h-screen max-w-5xl mx-auto">
                    {/* Header */}
                    <div className="h-16 border-b border-slate-800 flex items-center justify-between px-6 bg-slate-900/50 backdrop-blur">
                        <div className="flex items-center gap-3">
                            <div className={`w-3 h-3 rounded-full ${isSpeaking ? 'bg-green-500 animate-pulse' : 'bg-slate-600'}`}></div>
                            <div>
                                <h2 className="font-semibold text-white">{config.patientName} ({config.patientAge})</h2>
                                <span className="text-xs text-slate-400 uppercase tracking-wider">{config.scenario.replace('_', ' ')}</span>
                            </div>
                        </div>
                        <div className="flex items-center gap-4">
                            <div className="px-3 py-1 rounded-full bg-slate-800 text-xs text-cyan-400 border border-slate-700">
                                Current State: {currentEmotion.toUpperCase()}
                            </div>
                            <button 
                                onClick={generateReport}
                                className="text-sm bg-red-500/10 text-red-400 px-4 py-2 rounded hover:bg-red-500/20 transition border border-red-500/30"
                            >
                                End Session
                            </button>
                        </div>
                    </div>

                    {/* Chat Area */}
                    <div className="flex-1 overflow-y-auto p-6 space-y-6 custom-scrollbar">
                        {conversation.length === 0 && (
                            <div className="text-center text-slate-500 mt-20">
                                <Icon name="mic" size={48} className="mx-auto mb-4 opacity-50" />
                                <p>Press the microphone button to start the consultation.</p>
                                <p className="text-sm mt-2">Introduce yourself as the doctor.</p>
                            </div>
                        )}
                        
                        {conversation.map((turn, i) => (
                            <div key={i} className={`flex ${turn.role === 'doctor' ? 'justify-end' : 'justify-start'}`}>
                                <div className={`max-w-[80%] rounded-2xl p-4 ${
                                    turn.role === 'doctor' 
                                        ? 'bg-cyan-600 text-white rounded-tr-none' 
                                        : 'bg-slate-800 text-slate-200 rounded-tl-none border border-slate-700'
                                }`}>
                                    <p className="text-lg leading-relaxed">{turn.text}</p>
                                    {turn.role === 'patient' && turn.thought && (
                                        <div className="mt-3 pt-3 border-t border-slate-700/50">
                                            <p className="text-xs text-slate-400 italic flex gap-2">
                                                <Icon name="brain-circuit" size={14} />
                                                Internal: "{turn.thought}"
                                            </p>
                                        </div>
                                    )}
                                </div>
                            </div>
                        ))}
                        
                        {loading && (
                            <div className="flex justify-start">
                                <div className="bg-slate-800 rounded-2xl rounded-tl-none p-4 flex gap-2 items-center text-slate-400 text-sm">
                                    <div className="w-2 h-2 bg-slate-500 rounded-full animate-bounce" style={{animationDelay: '0ms'}}></div>
                                    <div className="w-2 h-2 bg-slate-500 rounded-full animate-bounce" style={{animationDelay: '150ms'}}></div>
                                    <div className="w-2 h-2 bg-slate-500 rounded-full animate-bounce" style={{animationDelay: '300ms'}}></div>
                                    Thinking...
                                </div>
                            </div>
                        )}
                        <div ref={chatEndRef}></div>
                    </div>

                    {/* Controls */}
                    <div className="h-32 bg-slate-900 border-t border-slate-800 flex items-center justify-center relative">
                        <button 
                            onClick={() => {
                                if (isRecording) {
                                    recognitionRef.current?.stop();
                                } else {
                                    recognitionRef.current?.start();
                                    setIsRecording(true);
                                }
                            }}
                            disabled={loading || isSpeaking}
                            className={`
                                w-20 h-20 rounded-full flex items-center justify-center transition-all duration-300
                                ${isRecording ? 'bg-red-500 mic-pulse text-white' : 'bg-cyan-500 hover:bg-cyan-400 text-slate-900'}
                                ${loading || isSpeaking ? 'opacity-50 cursor-not-allowed grayscale' : 'shadow-lg shadow-cyan-500/20'}
                            `}
                        >
                            <Icon name={isRecording ? "mic-off" : "mic"} size={32} />
                        </button>
                        
                        <div className="absolute right-8 bottom-8 text-xs text-slate-600 hidden md:block">
                            Uses Web Speech API & Gemini
                        </div>
                    </div>
                </div>
            );

            const ReportView = () => (
                <div className="p-6 md:p-12 max-w-6xl mx-auto min-h-screen">
                    <div className="flex items-center justify-between mb-8">
                        <div>
                            <h1 className="text-3xl font-bold text-white mb-2">Performance Evaluation</h1>
                            <p className="text-slate-400">Dr. User vs. Patient {config.patientName}</p>
                        </div>
                        <button onClick={() => setView('setup')} className="bg-slate-800 hover:bg-slate-700 text-white px-6 py-2 rounded-lg transition">
                            New Session
                        </button>
                    </div>

                    <div className="grid grid-cols-1 md:grid-cols-3 gap-6 mb-8">
                        <ScoreCard title="Empathy" score={evaluation.empathy_score} icon="heart" />
                        <ScoreCard title="Clarity" score={evaluation.clarity_score} icon="message-square" />
                        <ScoreCard title="Emotional Intelligence" score={evaluation.emotional_intelligence_score} icon="brain" />
                    </div>

                    <div className="grid grid-cols-1 lg:grid-cols-2 gap-8">
                        <div className="glass-panel p-6 rounded-xl">
                            <h3 className="text-xl font-semibold text-green-400 mb-4 flex items-center gap-2">
                                <Icon name="check-circle" /> Key Strengths
                            </h3>
                            <ul className="space-y-2">
                                {evaluation.key_strengths.map((s, i) => (
                                    <li key={i} className="flex gap-2 text-slate-300">
                                        <span className="text-green-500">•</span> {s}
                                    </li>
                                ))}
                            </ul>
                        </div>

                        <div className="glass-panel p-6 rounded-xl">
                            <h3 className="text-xl font-semibold text-amber-400 mb-4 flex items-center gap-2">
                                <Icon name="alert-triangle" /> Areas for Improvement
                            </h3>
                            <ul className="space-y-2">
                                {evaluation.areas_for_improvement.map((s, i) => (
                                    <li key={i} className="flex gap-2 text-slate-300">
                                        <span className="text-amber-500">•</span> {s}
                                    </li>
                                ))}
                            </ul>
                        </div>
                    </div>

                    <div className="mt-8 glass-panel p-8 rounded-xl border-l-4 border-cyan-500">
                        <h3 className="text-xl font-semibold text-white mb-4">Detailed Feedback</h3>
                        <p className="text-slate-300 leading-relaxed mb-6">{evaluation.specific_feedback}</p>
                        
                        <h4 className="text-lg font-semibold text-cyan-400 mb-4">Coaching: Alternative Phrasing</h4>
                        <div className="space-y-4">
                            {evaluation.better_alternatives.map((alt, i) => (
                                <div key={i} className="bg-slate-900/50 p-4 rounded-lg">
                                    <div className="text-red-400 text-sm mb-1 line-through opacity-70">"{alt.original}"</div>
                                    <div className="text-green-400 font-medium text-lg mb-2">"{alt.suggestion}"</div>
                                    <div className="text-slate-500 text-xs uppercase tracking-wide">Why: {alt.reason}</div>
                                </div>
                            ))}
                        </div>
                    </div>
                </div>
            );

            const ScoreCard = ({ title, score, icon }) => (
                <div className="glass-panel p-6 rounded-xl relative overflow-hidden group">
                    <div className="absolute right-0 top-0 opacity-10 transform translate-x-4 -translate-y-4 group-hover:scale-110 transition">
                        <Icon name={icon} size={100} />
                    </div>
                    <h3 className="text-slate-400 font-medium mb-2">{title}</h3>
                    <div className="flex items-baseline gap-2">
                        <span className={`text-5xl font-bold ${
                            score >= 80 ? 'text-green-400' : score >= 60 ? 'text-amber-400' : 'text-red-400'
                        }`}>{score}</span>
                        <span className="text-slate-500">/100</span>
                    </div>
                    <div className="w-full bg-slate-800 h-2 mt-4 rounded-full overflow-hidden">
                        <div 
                            className={`h-full rounded-full transition-all duration-1000 ${
                                score >= 80 ? 'bg-green-500' : score >= 60 ? 'bg-amber-500' : 'bg-red-500'
                            }`}
                            style={{ width: `${score}%` }}
                        ></div>
                    </div>
                </div>
            );

            // --- Main Render Switch ---
            return (
                <div className="min-h-screen bg-gradient-to-br from-slate-900 via-slate-900 to-slate-800 text-slate-100 selection:bg-cyan-500/30">
                    {view === 'setup' && <SetupView />}
                    {view === 'sim' && <SimulationView />}
                    {view === 'report' && <ReportView />}
                    {view === 'architecture' && <ArchitectureView />}
                </div>
            );
        }

        const root = ReactDOM.createRoot(document.getElementById('root'));
        root.render(<App />);
    </script>
</body>
</html>